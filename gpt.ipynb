{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56b48507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from model.gpt2 import CustomGPT2\n",
    "from torcheval.metrics import BinaryAUROC, BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryConfusionMatrix, BinaryAUPRC, BinaryAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ff4ea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'mcmed' # penn, mcmed, physionet\n",
    "CONTEXT_LENGTH = 1024\n",
    "TOKENIZER_PATH = f'tokenizer/{DATASET}_tokenizer.json'\n",
    "CKPT_PATH = f'checkpoints/{DATASET}/{DATASET}_gpt2.pth'\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "BATCH_SIZE = 16\n",
    "THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6818a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SepsisDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, context_length):\n",
    "        self.samples, labels = [], []\n",
    "        data['input'] = data.apply(lambda x: list(x['demo_str']) + list(x['input']), axis=1)\n",
    "        data['input'] = data['input'].apply(lambda x: x[-context_length:] if len(x) > context_length else x)\n",
    "        data = data[['pat_enc_csn_id', 'input', 'time', 'label']]\n",
    "        \n",
    "        for _, d in data.iterrows():\n",
    "            label = d['label']\n",
    "            self.samples.append(d)\n",
    "            labels.append(label)\n",
    "\n",
    "        self.index_map = list(range(len(self.samples)))\n",
    "        random.shuffle(self.index_map)\n",
    "\n",
    "        _, counts = torch.unique(torch.tensor(labels), return_counts=True)\n",
    "        print(f\"Original: {counts}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[self.index_map[idx]] \n",
    "        label = float(sample['label'])\n",
    "        event = list(sample['input'])\n",
    "        time = sample['time']\n",
    "        return event, time, label\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        events = [item[0] for item in batch]\n",
    "        times = [item[1] for item in batch]\n",
    "        labels = [item[2] for item in batch]\n",
    "        labels = torch.tensor(labels)\n",
    "        return events, times, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "564deb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOKENIZER\n",
    "tokenizer = PreTrainedTokenizerFast(tokenizer_file=TOKENIZER_PATH)\n",
    "tokenizer.eos_token = '[EOS]'\n",
    "tokenizer.sep_token = '[SEP]'\n",
    "tokenizer.bos_token = '[BOS]'\n",
    "tokenizer.pad_token = '[PAD]'\n",
    "tokenizer.cls_token = '[CLS]'\n",
    "tokenizer.mask_token = '[MASK]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e14fe04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "# LOAD MODEL\n",
    "model = CustomGPT2(vocab_size=len(tokenizer), num_classes=1)\n",
    "lmhead_state_dict = torch.load(CKPT_PATH, map_location=DEVICE, weights_only=True)\n",
    "load_result = model.load_state_dict(lmhead_state_dict, strict=False)\n",
    "print(load_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48582353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "df = pd.read_parquet(f'data/{DATASET}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "221f1b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12b89dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: tensor([30,  2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# CREATE DATALOADER\n",
    "train = SepsisDataset(df, CONTEXT_LENGTH)\n",
    "test_loader = torch.utils.data.DataLoader(train, collate_fn=SepsisDataset.collate_fn, batch_size=BATCH_SIZE, shuffle=True)\n",
    "iter = tqdm(test_loader, total=len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "683962fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize metrics\n",
    "auroc = BinaryAUROC().to(DEVICE)\n",
    "auprc = BinaryAUPRC().to(DEVICE)\n",
    "f1 = BinaryF1Score().to(DEVICE)\n",
    "precision = BinaryPrecision().to(DEVICE)\n",
    "recall = BinaryRecall().to(DEVICE)\n",
    "confusion_matrix = BinaryConfusionMatrix().to(DEVICE)\n",
    "accuracy = BinaryAccuracy().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce48eea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event, time, target in iter:\n",
    "    with torch.no_grad():\n",
    "        target = target.to(DEVICE).long()\n",
    "        \n",
    "        # GET INPUTS\n",
    "        max_len = max(len(i) for i in event)\n",
    "        tokens = tokenizer(event, return_tensors=\"pt\", is_split_into_words=True, padding=True, return_attention_mask=True)\n",
    "        input_ids = tokens[\"input_ids\"].to(DEVICE)   \n",
    "        attention_masks = tokens[\"attention_mask\"].to(DEVICE) \n",
    "\n",
    "        times = [F.pad(torch.tensor(r, dtype=torch.float32), (0, max_len - len(r))).round(decimals=2)  for r in time]\n",
    "        times = torch.stack(times, dim=0).to(DEVICE)  \n",
    "\n",
    "        # INFERENCE\n",
    "        output = model.to(DEVICE)(input_ids.to(DEVICE), times.to(DEVICE), attention_masks.to(DEVICE))\n",
    "        output = torch.sigmoid(output).squeeze(-1) \n",
    "\n",
    "        preds = output >= THRESHOLD\n",
    "        f1.update(preds, target)\n",
    "        precision.update(preds, target)\n",
    "        recall.update(preds, target)\n",
    "        auroc.update(output, target)\n",
    "        auprc.update(output, target)\n",
    "        confusion_matrix.update(preds, target)\n",
    "        accuracy.update(preds, target)\n",
    "        \n",
    "        iter.set_description(f\"Running...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7059da2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1.compute()\n",
    "auc = auroc.compute()\n",
    "auprc = auprc.compute()\n",
    "precision = precision.compute()\n",
    "recall = recall.compute()\n",
    "conf_matrix = confusion_matrix.compute()\n",
    "test_acc = accuracy.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbd1ccca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.8438, F1: 0.2857, AUC: 0.8333, AUPRC: 0.2361\n",
      "tensor([[26.,  4.],\n",
      "        [ 1.,  1.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(f\"Acc: {test_acc:.4f}, F1: {f1:.4f}, AUC: {auc:.4f}, AUPRC: {auprc:.4f}\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f046884a-f138-47ad-8ed8-f05e6a11cc69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
